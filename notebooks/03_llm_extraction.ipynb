{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c06ff5",
   "metadata": {},
   "source": [
    "# 03_llm_extraction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4545814",
   "metadata": {},
   "source": [
    "# LLM Enhancement\n",
    "To improve the accuracy of invoice data extraction, we introduce an LLM-based correction layer over the existing OCR and regex pipeline. The system first processes documents through OCR—using native text extraction for PDFs and EasyOCR for images—and standardizes the results via regex before storing them in CSV format.\n",
    "\n",
    "**Option A** uses a text-based LLM, *Gemini* , which receives the OCR output and regex-cleaned data. It reformats the extracted fields into a structured table format for each invoice and outputs a confidence score. A validation script checks for missing or invalid fields; if confidence is low or errors are detected, **Option B** is triggered.\n",
    "\n",
    "**Option B** employs a visual-text LLM, such as *Gemini*, which takes the same input as Option A along with the document image path to refine and correct the extracted data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9774b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders and CSV files created successfully:\n",
      "- c:\\Stealth AI\\Clean Reader\\data\\processed\\llm\\llm_invoices.csv\n",
      "- c:\\Stealth AI\\Clean Reader\\data\\processed\\llm\\llm_lineitems.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define base paths \n",
    "root_folder = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "processed_folder = os.path.join(root_folder, \"data\", \"processed\")\n",
    "\n",
    "# Create new folders \n",
    "llm_folder = os.path.join(processed_folder, \"llm\")\n",
    "\n",
    "os.makedirs(llm_folder, exist_ok=True)\n",
    "\n",
    "# Define file paths \n",
    "llm_invoices_path = os.path.join(llm_folder, \"llm_invoices.csv\")\n",
    "llm_lineitems_path = os.path.join(llm_folder, \"llm_lineitems.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Define column structures \n",
    "invoices_columns = [\"file_path\", \"invoice_id\", \"vendor\", \"date\", \"total\", \"invoice_number\"]\n",
    "lineitems_columns = [\"file_path\", \"invoice_id\", \"description\", \"quantity\", \"unit_price\", \"total\"]\n",
    "\n",
    "# Create empty DataFrames and save as CSVs \n",
    "pd.DataFrame(columns=invoices_columns).to_csv(llm_invoices_path, index=False)\n",
    "pd.DataFrame(columns=lineitems_columns).to_csv(llm_lineitems_path, index=False)\n",
    "\n",
    "\n",
    "print(\"Folders and CSV files created successfully:\")\n",
    "print(f\"- {llm_invoices_path}\")\n",
    "print(f\"- {llm_lineitems_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92976bc5",
   "metadata": {},
   "source": [
    "# LLM Rationale\n",
    "We first use the Google Gemini 1.5 Flash API (text) since it’s less compute-intensive. If confidence is low or regex rules fail (e.g., missing values or letters in numeric fields), we fall back to the Gemini 1.5 Flash API (vision + LLM). This approach reserves paid tokens for complex cases, with the confidence threshold adjustable based on invoice difficulty or readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f48dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"My key here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a166aa",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbe50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "\n",
    "# --- Initialize Gemini client safely ---\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise EnvironmentError(\"Missing GEMINI_API_KEY. Please set it as an environment variable.\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "\n",
    "def _clean_json_output(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans Gemini output by removing markdown code fences (```json, ```),\n",
    "    stripping whitespace, and ensuring only valid JSON remains.\n",
    "    \"\"\"\n",
    "    if not raw_text:\n",
    "        raise ValueError(\"Model returned empty response.\")\n",
    "\n",
    "    # Remove markdown-style code fences\n",
    "    cleaned = re.sub(r\"^```(?:json)?|```$\", \"\", raw_text.strip(), flags=re.MULTILINE).strip()\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def extract_invoice_json(clean_text: str, invoice_data: list, lineitems_data: list) -> dict:\n",
    "    \"\"\"\n",
    "    Send cleaned invoice text + regex-extracted data to Gemini and return structured JSON.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an expert AI that extracts structured invoice data from semi-structured text.\n",
    "\n",
    "Rules:\n",
    "1. Output ONLY valid JSON, no explanations.\n",
    "2. Do NOT wrap JSON in markdown code fences (no ```json or ```).\n",
    "3. Each line item may contain a description, size, and brand together — separate them correctly.\n",
    "4. Make sure description doesn't include size or company/brand name. Size and brand should be separate fields.\n",
    "5. Include a confidence score between 0 and 1 based on extraction reliability.\n",
    "6. If a field is missing, use null.\n",
    "7. Ensure totals match quantity * unit_price if possible, otherwise keep the total from the invoice text.\n",
    "8. Do not include fuel surcharges or taxes as regular line items.\n",
    "9. Use the following schema strictly:\n",
    "\n",
    "{{\n",
    "  \"llm_invoices\": {{\n",
    "    \"file_path\": str,\n",
    "    \"vendor\": str,\n",
    "    \"date\": str,\n",
    "    \"total\": float,\n",
    "    \"invoice_number\": str\n",
    "  }},\n",
    "  \"llm_lineitems\": [\n",
    "    {{\n",
    "      \"invoice_number\": str,\n",
    "      \"description\": str,\n",
    "      \"quantity\": float or null,\n",
    "      \"unit_price\": float or null,\n",
    "      \"total\": float or null\n",
    "    }}\n",
    "  ],\n",
    "  \"confidence\": float\n",
    "}}\n",
    "\n",
    "Cleaned text:\n",
    "{clean_text}\n",
    "\n",
    "Regex invoice data:\n",
    "{json.dumps(invoice_data, indent=2)}\n",
    "\n",
    "Regex line items data:\n",
    "{json.dumps(lineitems_data, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    # --- Call Gemini model ---\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    response = model.generate_content(prompt)\n",
    "    raw_text = response.text.strip() if response and response.text else \"\"\n",
    "\n",
    "    # --- Clean & parse JSON ---\n",
    "    cleaned = _clean_json_output(raw_text)\n",
    "\n",
    "    try:\n",
    "        parsed_json = json.loads(cleaned)\n",
    "        return parsed_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(\n",
    "            f\"Model did not return valid JSON even after cleaning. \"\n",
    "            f\"Error: {e}\\nRaw output:\\n{raw_text}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     clean_text = \"\"\"pacific flood 379183 mporters inc 18620 80th court south, bldg: f kent, wa 980\n",
    "# www-pacificfoodimporters.com purchase order no terms order no cust id order date | date sales rep net 7 days\n",
    "# 08/04/2025 08/05/2025 18\n",
    "# sold to: westmans bagel { caffe dba\n",
    "# ship to: westmans bagel { caffe dba tetia llc # 1 tetia llc 2925 223rd pl sw 5201 university way ne b brier , wa usa seattlebrier , wa usa\n",
    "# 5 fax: routelstop: 03-tu 6 ship via: of\n",
    "# 1 product id ordered shipped description size brand st gross wt price per amount\n",
    "# 102950 8 000 8 . ooo/cs flour power 24 . 063 cs 192 50 graincraft\n",
    "# 157301 1.000 1 000 cs sesam seeds white+ 4 x 80 _ 250 cs 80 25 marca croc\n",
    "# 33425 1.000 1.000 cs jalapeno sliced 6 # 51.329 cs 51.33 savor\n",
    "# 78825 x 1.000 1.000 ea currants 29.203 ea 29 20\n",
    "# 3210 3 . 000 3 . 0o/cs milk oat 12 x 32 oz 84 . 39.948 cs 119.84 oatley\n",
    "# 109950 1.000 1.oo0/cs sugar granulated cane 26 . 28 . 587 cs 28 59 ceh sugar\n",
    "# 191928 1_ 000 1_ ooolcs eggs liquid 2 x 95.225 cs 95.23 papettis\n",
    "# total weight] 626 _ 67 sub total 596 _ 94 : st = status code: discount taxed t sub s freight tax total cash check# charge paid on acct total 596.94\"\"\"\n",
    "\n",
    "#     invoice_data = [\n",
    "#         {\n",
    "#             \"file_path\": r\"C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (1).jpg\",\n",
    "#             \"invoice_id\": 379183,\n",
    "#             \"vendor\": \"pacificfoodimporters\",\n",
    "#             \"date\": \"08/05/2025\",\n",
    "#             \"total\": 596.94,\n",
    "#             \"invoice_number\": \"379183\"\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     lineitems_data = [\n",
    "#         {\"description\": \"063 192 50 graincraft 157301\", \"quantity\": 0, \"unit_price\": None, \"total\": 1.00},\n",
    "#         {\"description\": \"80 25 marca croc 33425\", \"quantity\": 250, \"unit_price\": 0.0, \"total\": 1.00},\n",
    "#         {\"description\": \"jalapeno sliced 6\", \"quantity\": 1, \"unit_price\": 51.32, \"total\": 51.32},\n",
    "#         {\"description\": \"\", \"quantity\": 9, \"unit_price\": 5.7, \"total\": 51.33},\n",
    "#         {\"description\": \"x 78825\", \"quantity\": 0, \"unit_price\": 0.0, \"total\": 1.00},\n",
    "#         {\"description\": \"currants\", \"quantity\": 1, \"unit_price\": 29.2, \"total\": 29.20},\n",
    "#         {\"description\": \"\", \"quantity\": 39, \"unit_price\": 3.07, \"total\": 119.84},\n",
    "#         {\"description\": \"x 2\", \"quantity\": 47.61, \"unit_price\": None, \"total\": 95.22},\n",
    "#         {\"description\": \"\", \"quantity\": 5, \"unit_price\": 19.05, \"total\": 95.23}\n",
    "#     ]\n",
    "\n",
    "#     result_json = extract_invoice_json(clean_text, invoice_data, lineitems_data)\n",
    "#     print(json.dumps(result_json, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8edb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import mimetypes\n",
    "import google.generativeai as genai\n",
    "\n",
    "def visual_extract_invoice_json(existing_json: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Takes the JSON output from extract_invoice_json() and the invoice image/PDF (from file_path).\n",
    "    Uses Gemini multimodal vision model to correct missing or incorrect fields.\n",
    "\n",
    "    Args:\n",
    "        existing_json (dict): JSON from extract_invoice_json().\n",
    "\n",
    "    Returns:\n",
    "        dict: Corrected JSON, same schema.\n",
    "    \"\"\"\n",
    "    # --- Validate file path from JSON ---\n",
    "    file_path = (\n",
    "        existing_json.get(\"llm_invoices\", {}).get(\"file_path\")\n",
    "        if existing_json.get(\"llm_invoices\")\n",
    "        else None\n",
    "    )\n",
    "    if not file_path or not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found or invalid: {file_path}\")\n",
    "\n",
    "    # --- Load file for Gemini ---\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = \"image/jpeg\"  # fallback default\n",
    "    file_obj = genai.upload_file(file_path, mime_type=mime_type)\n",
    "\n",
    "    # --- Construct correction prompt ---\n",
    "    prompt = f\"\"\"\n",
    "You are an expert invoice extraction AI.\n",
    "You are given a JSON that was generated from an OCR process. \n",
    "The JSON may have missing fields or incorrect values.\n",
    "\n",
    "Your task:\n",
    "1. Use the provided invoice image/PDF to **verify and correct** all data.\n",
    "2. Make sure **no field is null or missing** if the information is visible in the document.\n",
    "3. Keep the same JSON schema.\n",
    "4. If a field is not visible at all, use null, not a guess.\n",
    "5. In line items, the \"description\" field may incorrectly include product size or brand name.\n",
    "   - Correct format: description / size / brand\n",
    "   - Only the **first part (product name)** should go in \"description\".\n",
    "   - The rest (size, brand) should NOT appear in the \"description\" field.\n",
    "   - Example corrections:\n",
    "       * \"flour power 50 lb graincraft\" → description=\"flour power\", size=\"50 lb\", brand=\"graincraft\"\n",
    "       * \"jalapeno sliced 6#10 savor\" → description=\"jalapeno sliced\", size=\"6#10\", brand=\"savor\"\n",
    "   - For this schema, **only keep description, quantity, unit_price, total**.\n",
    "     (size and brand need not appear unless your schema includes them explicitly.)\n",
    "6. Ensure totals = quantity × unit_price wherever possible.\n",
    "7. Recalculate confidence between 0 and 1 based on correction reliability.\n",
    "8. Output **only valid JSON** (no markdown or commentary).\n",
    "\n",
    "Here is the current JSON to correct:\n",
    "{json.dumps(existing_json, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    # --- Call Gemini multimodal model ---\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    response = model.generate_content([prompt, file_obj])\n",
    "    raw_text = response.text.strip() if response and response.text else \"\"\n",
    "    cleaned = _clean_json_output(raw_text)\n",
    "\n",
    "    try:\n",
    "        corrected_json = json.loads(cleaned)\n",
    "        return corrected_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(\n",
    "            f\"Gemini did not return valid JSON. Error: {e}\\nRaw output:\\n{raw_text}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example: using JSON from previous extract_invoice_json() run\n",
    "#     previous_json = {\n",
    "#         \"llm_invoices\": {\n",
    "#             \"file_path\": r\"C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (1).jpg\",\n",
    "#             \"vendor\": \"pacificfoodimporters\",\n",
    "#             \"date\": \"08/05/2025\",\n",
    "#             \"total\": 596.94,\n",
    "#             \"invoice_number\": \"379183\"\n",
    "#         },\n",
    "#         \"llm_lineitems\": [\n",
    "#             {\n",
    "#                 \"invoice_number\": \"379183\",\n",
    "#                 \"description\": \"flour power 50 lb graincraft\",\n",
    "#                 \"quantity\": 8.0,\n",
    "#                 \"unit_price\": None,\n",
    "#                 \"total\": 192.50\n",
    "#             },\n",
    "#             {\n",
    "#                 \"invoice_number\": \"379183\",\n",
    "#                 \"description\": \"jalapeno sliced 6#10 savor\",\n",
    "#                 \"quantity\": 1.0,\n",
    "#                 \"unit_price\": 51.33,\n",
    "#                 \"total\": 51.33\n",
    "#             },\n",
    "#             {\n",
    "#                 \"invoice_number\": \"379183\",\n",
    "#                 \"description\": \"currants 29.2 ea\",\n",
    "#                 \"quantity\": 1.0,\n",
    "#                 \"unit_price\": 29.20,\n",
    "#                 \"total\": 29.20\n",
    "#             },\n",
    "#             {\n",
    "#                 \"invoice_number\": \"379183\",\n",
    "#                 \"description\": \"milk oat 12x32oz oatley\",\n",
    "#                 \"quantity\": 3.0,\n",
    "#                 \"unit_price\": 39.95,\n",
    "#                 \"total\": 119.84\n",
    "#             },\n",
    "#             {\n",
    "#                 \"invoice_number\": \"379183\",\n",
    "#                 \"description\": \"sugar granulated cane 25 lb ceh sugar\",\n",
    "#                 \"quantity\": 1.0,\n",
    "#                 \"unit_price\": 28.59,\n",
    "#                 \"total\": 28.59\n",
    "#             },\n",
    "#             {\n",
    "#                 \"invoice_number\": \"379183\",\n",
    "#                 \"description\": \"eggs liquid 2x95 papettis\",\n",
    "#                 \"quantity\": 1.0,\n",
    "#                 \"unit_price\": 95.23,\n",
    "#                 \"total\": 95.23\n",
    "#             }\n",
    "#         ],\n",
    "#         \"confidence\": 0.93\n",
    "#     }\n",
    "\n",
    "#     corrected = visual_extract_invoice_json(previous_json)\n",
    "#     print(json.dumps(corrected, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a62db63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# Root \n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "PROCESSED = os.path.join(ROOT, \"data\", \"processed\")\n",
    "REGEX_FOLDER = os.path.join(PROCESSED, \"regex\")\n",
    "\n",
    "LLM_FOLDER = os.path.join(PROCESSED, \"llm\")\n",
    "os.makedirs(LLM_FOLDER, exist_ok=True)\n",
    "\n",
    "LLM_INVOICES_PATH = os.path.join(LLM_FOLDER, \"llm_invoices.csv\")\n",
    "LLM_LINEITEMS_PATH = os.path.join(LLM_FOLDER, \"llm_lineitems.csv\")\n",
    "\n",
    "# Input CSV filenames (inside REGEX_FOLDER)\n",
    "REGEX_CLEANED_INVOICES_CSV = os.path.join(PROCESSED, \"regex_cleaned_invoices.csv\")\n",
    "REGEX_INVOICES_CSV = os.path.join(REGEX_FOLDER, \"regex_invoices.csv\")        # optional\n",
    "REGEX_LINEITEMS_CSV = os.path.join(REGEX_FOLDER, \"regex_lineitems.csv\")\n",
    "\n",
    "# Validation / business parameters\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "# Target date format requested (interpreted as dd-mm-YYYY with dashes)\n",
    "TARGET_DATE_FORMAT = \"%d-%m-%Y\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0048b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_as_dicts(path: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Return list of rows as dicts from CSV. If file missing, return empty list.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Warning: file not found: {path}\")\n",
    "        return []\n",
    "    with open(path, newline='', encoding='utf-8') as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        return [row for row in reader]\n",
    "\n",
    "def write_csv_append(path: str, rows: List[Dict[str, Any]], fieldnames: List[str]) -> None:\n",
    "    \"\"\"Append rows into CSV; create file and header if doesn't exist.\"\"\"\n",
    "    file_exists = os.path.exists(path)\n",
    "    with open(path, 'a', newline='', encoding='utf-8') as fh:\n",
    "        writer = csv.DictWriter(fh, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow({k: (\"\" if r.get(k) is None else r.get(k)) for k in fieldnames})\n",
    "\n",
    "def normalize_date(value: str) -> Tuple[Any, str]:\n",
    "    \"\"\"\n",
    "    Try to parse a date string and return (parsed_date_str_or_None, error_message).\n",
    "    Target format is TARGET_DATE_FORMAT (dd-mm-YYYY).\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None, \"missing\"\n",
    "    v = str(value).strip()\n",
    "    if not v:\n",
    "        return None, \"empty string\"\n",
    "    # Common separators: '/', '-', '.', whitespace. Replace to uniform then try several formats.\n",
    "    v_clean = re.sub(r'[\\\\/\\.]', '-', v)\n",
    "    # possible input formats\n",
    "    candidates = [\n",
    "        \"%m-%d-%Y\", \"%m-%d-%y\", \"%d-%m-%Y\", \"%d-%m-%y\",\n",
    "        \"%Y-%m-%d\", \"%Y-%d-%m\", \"%d %b %Y\", \"%d %B %Y\",\n",
    "        \"%m/%d/%Y\", \"%d/%m/%Y\"\n",
    "    ]\n",
    "    for fmt in candidates:\n",
    "        try:\n",
    "            dt = datetime.strptime(v_clean, fmt)\n",
    "            return dt.strftime(TARGET_DATE_FORMAT), \"\"\n",
    "        except Exception:\n",
    "            continue\n",
    "    # try to extract digits (e.g., 08/05/2025 -> 08-05-2025)\n",
    "    digits = re.findall(r'\\d+', v)\n",
    "    if len(digits) >= 3:\n",
    "        try:\n",
    "            # use last three as month/day/year or day/month/year heuristics\n",
    "            d0, d1, d2 = digits[-3], digits[-2], digits[-1]\n",
    "            # sensible guess: if first > 12 then it is day\n",
    "            if int(d0) > 12:\n",
    "                dt = datetime(int(d2), int(d1), int(d0))\n",
    "            else:\n",
    "                dt = datetime(int(d2), int(d0), int(d1))\n",
    "            return dt.strftime(TARGET_DATE_FORMAT), \"\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None, f\"unparseable date: {value}\"\n",
    "\n",
    "def to_float_safe(value) -> Tuple[Any, str]:\n",
    "    \"\"\"Convert to float if possible. Returns (float_or_None, error_reason).\"\"\"\n",
    "    if value is None:\n",
    "        return None, \"missing\"\n",
    "    try:\n",
    "        if isinstance(value, (float, int)):\n",
    "            return float(value), \"\"\n",
    "        s = str(value).strip().replace(',', '').replace('$', '')\n",
    "        if s == \"\":\n",
    "            return None, \"empty\"\n",
    "        return float(s), \"\"\n",
    "    except Exception as e:\n",
    "        return None, f\"not_a_number ({value})\"\n",
    "\n",
    "def to_str_safe(value) -> Tuple[Any, str]:\n",
    "    if value is None:\n",
    "        return None, \"missing\"\n",
    "    s = str(value).strip()\n",
    "    if s == \"\":\n",
    "        return None, \"empty\"\n",
    "    return s, \"\"\n",
    "\n",
    "def validate_invoice_json(result_json: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"\n",
    "    Validate the JSON according to your rules.\n",
    "    Return (is_valid, list_of_issues). If invalid, list of human-readable issues.\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    # top-level checks\n",
    "    inv = result_json.get(\"llm_invoices\")\n",
    "    if not inv:\n",
    "        issues.append(\"llm_invoices missing\")\n",
    "        return False, issues\n",
    "\n",
    "    # file_path check\n",
    "    fp = inv.get(\"file_path\")\n",
    "    fp_s, fp_err = to_str_safe(fp)\n",
    "    if fp_err:\n",
    "        issues.append(f\"file_path: {fp_err}\")\n",
    "    else:\n",
    "        # ensure path matches existing file\n",
    "        if not os.path.exists(fp_s):\n",
    "            issues.append(f\"file_path does not exist on disk: {fp_s}\")\n",
    "\n",
    "    # vendor\n",
    "    vendor_s, vendor_err = to_str_safe(inv.get(\"vendor\"))\n",
    "    if vendor_err:\n",
    "        issues.append(f\"vendor: {vendor_err}\")\n",
    "\n",
    "    # date\n",
    "    date_val = inv.get(\"date\")\n",
    "    date_norm, date_err = normalize_date(date_val)\n",
    "    if date_err:\n",
    "        issues.append(f\"date: {date_err}\")\n",
    "    else:\n",
    "        inv[\"date\"] = date_norm  # overwrite with normalized format\n",
    "\n",
    "    # total\n",
    "    total_val, total_err = to_float_safe(inv.get(\"total\"))\n",
    "    if total_err:\n",
    "        issues.append(f\"total: {total_err}\")\n",
    "    else:\n",
    "        inv[\"total\"] = total_val\n",
    "\n",
    "    # invoice_number -> must be a string\n",
    "    invnum, invnum_err = to_str_safe(inv.get(\"invoice_number\"))\n",
    "    if invnum_err:\n",
    "        issues.append(f\"invoice_number: {invnum_err}\")\n",
    "    else:\n",
    "        inv[\"invoice_number\"] = invnum\n",
    "\n",
    "    # confidence\n",
    "    conf = result_json.get(\"confidence\")\n",
    "    conf_val, conf_err = to_float_safe(conf)\n",
    "    if conf_err:\n",
    "        issues.append(f\"confidence: {conf_err}\")\n",
    "    else:\n",
    "        result_json[\"confidence\"] = conf_val\n",
    "\n",
    "    # line items\n",
    "    lineitems = result_json.get(\"llm_lineitems\")\n",
    "    if not isinstance(lineitems, list) or len(lineitems) == 0:\n",
    "        issues.append(\"llm_lineitems missing or empty\")\n",
    "    else:\n",
    "        for idx, li in enumerate(lineitems):\n",
    "            # description\n",
    "            desc, desc_err = to_str_safe(li.get(\"description\"))\n",
    "            if desc_err:\n",
    "                # allow empty description to be flagged but continue\n",
    "                issues.append(f\"lineitem[{idx}].description: {desc_err}\")\n",
    "            else:\n",
    "                li[\"description\"] = desc\n",
    "            # quantity\n",
    "            qty, qty_err = to_float_safe(li.get(\"quantity\"))\n",
    "            if qty_err:\n",
    "                # quantity may be null for some items, we'll flag it\n",
    "                issues.append(f\"lineitem[{idx}].quantity: {qty_err}\")\n",
    "            else:\n",
    "                li[\"quantity\"] = qty\n",
    "            # unit_price\n",
    "            up, up_err = to_float_safe(li.get(\"unit_price\"))\n",
    "            if up_err:\n",
    "                issues.append(f\"lineitem[{idx}].unit_price: {up_err}\")\n",
    "            else:\n",
    "                li[\"unit_price\"] = up\n",
    "            # total\n",
    "            tval, t_err = to_float_safe(li.get(\"total\"))\n",
    "            if t_err:\n",
    "                issues.append(f\"lineitem[{idx}].total: {t_err}\")\n",
    "            else:\n",
    "                li[\"total\"] = tval\n",
    "\n",
    "            # basic arithmetic check (if both qty and unit_price present)\n",
    "            if isinstance(li.get(\"quantity\"), (float, int)) and isinstance(li.get(\"unit_price\"), (float, int)):\n",
    "                calc = round(li[\"quantity\"] * li[\"unit_price\"], 2)\n",
    "                if li.get(\"total\") is not None:\n",
    "                    # allow small rounding differences up to 0.05\n",
    "                    if abs(calc - li[\"total\"]) > 0.05:\n",
    "                        issues.append(f\"lineitem[{idx}] calc mismatch: qty*unit_price={calc} != total {li['total']}\")\n",
    "\n",
    "    # final validation decision\n",
    "    is_valid = (len(issues) == 0) and (result_json.get(\"confidence\", 0) >= CONFIDENCE_THRESHOLD)\n",
    "    return is_valid, issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9560aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting helpers to prepare inputs for extract_invoice_json\n",
    "\n",
    "def build_inputs_for_extractor(cleaned_row: Dict[str, str], lineitems_rows: List[Dict[str, str]]) -> Tuple[str, List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Build (clean_text, invoice_data, lineitems_data) in the format expected by extract_invoice_json.\n",
    "    `cleaned_row` is one row from regex_cleaned_invoices.csv (contains at least file_path and clean_text).\n",
    "    `lineitems_rows` are the rows from regex_lineitems.csv that match the file_path.\n",
    "    \"\"\"\n",
    "    clean_text = cleaned_row.get(\"cleaned_text\") or cleaned_row.get(\"clean_text\") or cleaned_row.get(\"clean text\") or \"\"\n",
    "    file_path = cleaned_row.get(\"file_path\") or cleaned_row.get(\"filepath\") or cleaned_row.get(\"FilePath\")\n",
    "    invoice_id = cleaned_row.get(\"id\") or cleaned_row.get(\"invoice_id\") or cleaned_row.get(\"invoice number\") or cleaned_row.get(\"invoice_number\")\n",
    "    invoice_number = cleaned_row.get(\"invoice_number\") or cleaned_row.get(\"invoice number\") or invoice_id\n",
    "    vendor = cleaned_row.get(\"vendor\") or \"\"\n",
    "    date = cleaned_row.get(\"date\") or \"\"\n",
    "    total = cleaned_row.get(\"total\") or \"\"\n",
    "\n",
    "    # invoice_data expects a list with one dict\n",
    "    invoice_data = [{\n",
    "        \"file_path\": file_path,\n",
    "        \"invoice_id\": int(invoice_id) if invoice_id and str(invoice_id).isdigit() else invoice_id,\n",
    "        \"vendor\": vendor,\n",
    "        \"date\": date,\n",
    "        \"total\": total,\n",
    "        \"invoice_number\": str(invoice_number) if invoice_number is not None else None\n",
    "    }]\n",
    "\n",
    "    # build lineitems_data list\n",
    "    lineitems_data = []\n",
    "    for row in lineitems_rows:\n",
    "        # use a best-effort mapping\n",
    "        desc = row.get(\"description\") or row.get(\"desc\") or row.get(\"Description\") or \"\"\n",
    "        qty = row.get(\"quantity\") or row.get(\"qty\") or row.get(\"Quantity\")\n",
    "        unit_price = row.get(\"unit_price\") or row.get(\"unitprice\") or row.get(\"price per\") or row.get(\"unit price\")\n",
    "        total_li = row.get(\"total\") or row.get(\"amount\") or row.get(\"line_total\")\n",
    "\n",
    "        # normalize numeric obvious empty markers\n",
    "        qty_val = None\n",
    "        try:\n",
    "            qty_val = float(str(qty).strip()) if qty not in (None, \"\") else None\n",
    "        except Exception:\n",
    "            qty_val = None\n",
    "\n",
    "        up_val = None\n",
    "        try:\n",
    "            up_val = float(str(unit_price).replace(',', '').strip()) if unit_price not in (None, \"\", \"0.0\") else (0.0 if str(unit_price).strip() in (\"0\", \"0.0\") else None)\n",
    "        except Exception:\n",
    "            up_val = None\n",
    "\n",
    "        total_val = None\n",
    "        try:\n",
    "            total_val = float(str(total_li).replace(',', '').strip()) if total_li not in (None, \"\") else None\n",
    "        except Exception:\n",
    "            total_val = None\n",
    "\n",
    "        lineitems_data.append({\n",
    "            \"description\": desc,\n",
    "            \"quantity\": qty_val,\n",
    "            \"unit_price\": up_val,\n",
    "            \"total\": total_val\n",
    "        })\n",
    "\n",
    "    return clean_text, invoice_data, lineitems_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad09721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main processing pipeline\n",
    "\n",
    "def process_all_regex_invoices():\n",
    "    cleaned_invoices = read_csv_as_dicts(REGEX_CLEANED_INVOICES_CSV)\n",
    "    if not cleaned_invoices:\n",
    "        print(\"No cleaned invoices found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    regex_lineitems = read_csv_as_dicts(REGEX_LINEITEMS_CSV)\n",
    "    # index lineitems by file_path for quick lookup\n",
    "    lineitems_index = {}\n",
    "    for row in regex_lineitems:\n",
    "        fp = row.get(\"file_path\") or row.get(\"filepath\") or row.get(\"FilePath\")\n",
    "        if not fp:\n",
    "            continue\n",
    "        lineitems_index.setdefault(fp, []).append(row)\n",
    "\n",
    "    # prepare collectors for CSV output\n",
    "    invoices_to_append = []\n",
    "    lineitems_to_append = []\n",
    "\n",
    "    for idx, c_row in enumerate(cleaned_invoices, start=1):\n",
    "        print(f\"\\nProcessing [{idx}/{len(cleaned_invoices)}] file_path: {c_row.get('file_path')}\")\n",
    "        file_path = c_row.get(\"file_path\")\n",
    "        matching_lineitems = lineitems_index.get(file_path, [])\n",
    "        clean_text, invoice_data, lineitems_data = build_inputs_for_extractor(c_row, matching_lineitems)\n",
    "\n",
    "        # call text-only extractor (assumes extract_invoice_json is defined)\n",
    "        try:\n",
    "            result_json = extract_invoice_json(clean_text, invoice_data, lineitems_data)\n",
    "        except Exception as e:\n",
    "            print(f\"extract_invoice_json raised an error: {e}\")\n",
    "            # If extract fails completely, fallback to visual directly (create minimal JSON)\n",
    "            result_json = {\n",
    "                \"llm_invoices\": {\n",
    "                    \"file_path\": file_path,\n",
    "                    \"vendor\": None,\n",
    "                    \"date\": None,\n",
    "                    \"total\": None,\n",
    "                    \"invoice_number\": None\n",
    "                },\n",
    "                \"llm_lineitems\": [],\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "\n",
    "        # Validate\n",
    "        is_valid, issues = validate_invoice_json(result_json)\n",
    "\n",
    "        went_visual = False\n",
    "        if (not is_valid) or (result_json.get(\"confidence\", 0) < CONFIDENCE_THRESHOLD):\n",
    "            # Log the reasons\n",
    "            print(\"Validation failed or low confidence. Issues:\")\n",
    "            for it in issues:\n",
    "                print(\"  -\", it)\n",
    "            print(\"Calling visual_extract_invoice_json to attempt correction...\")\n",
    "            went_visual = True\n",
    "            try:\n",
    "                corrected = visual_extract_invoice_json(result_json)\n",
    "                print(\"Visual correction returned. Re-validating...\")\n",
    "                # replace result_json with corrected\n",
    "                result_json = corrected\n",
    "                is_valid_after, issues_after = validate_invoice_json(result_json)\n",
    "                if not is_valid_after:\n",
    "                    print(\"Still some issues after visual correction:\")\n",
    "                    for it in issues_after:\n",
    "                        print(\"  -\", it)\n",
    "                else:\n",
    "                    print(\"Visual correction successful.\")\n",
    "                is_valid = is_valid_after\n",
    "                issues = issues_after\n",
    "            except Exception as e:\n",
    "                print(\"visual_extract_invoice_json raised an error:\", e)\n",
    "                # keep original result_json and mark as failed\n",
    "                is_valid = False\n",
    "\n",
    "        else:\n",
    "            print(f\"Text-only extraction OK. Confidence = {result_json.get('confidence', None)}\")\n",
    "\n",
    "        # Prepare rows to append into LLM CSVs (even if partially invalid, append corrected/available fields)\n",
    "        inv = result_json.get(\"llm_invoices\", {})\n",
    "        llm_inv_row = {\n",
    "            \"file_path\": inv.get(\"file_path\"),\n",
    "            \"invoice_id\": inv.get(\"invoice_number\") or inv.get(\"invoice_id\") or \"\",\n",
    "            \"vendor\": inv.get(\"vendor\"),\n",
    "            \"date\": inv.get(\"date\"),\n",
    "            \"total\": inv.get(\"total\"),\n",
    "            \"invoice_number\": inv.get(\"invoice_number\")\n",
    "        }\n",
    "        invoices_to_append.append(llm_inv_row)\n",
    "\n",
    "        # line items\n",
    "        for li in result_json.get(\"llm_lineitems\", []):\n",
    "            li_row = {\n",
    "                \"file_path\": inv.get(\"file_path\"),\n",
    "                \"invoice_id\": inv.get(\"invoice_number\"),\n",
    "                \"description\": li.get(\"description\"),\n",
    "                \"quantity\": li.get(\"quantity\"),\n",
    "                \"unit_price\": li.get(\"unit_price\"),\n",
    "                \"total\": li.get(\"total\")\n",
    "            }\n",
    "            lineitems_to_append.append(li_row)\n",
    "\n",
    "        # Print summary for this invoice\n",
    "        status = \"visual\" if went_visual else \"text-only\"\n",
    "        print(f\"Finished: {file_path} — method={status} — valid={is_valid} — confidence={result_json.get('confidence')}\")\n",
    "\n",
    "    # flush to CSVs\n",
    "    invoice_fieldnames = [\"file_path\", \"invoice_id\", \"vendor\", \"date\", \"total\", \"invoice_number\"]\n",
    "    lineitem_fieldnames = [\"file_path\", \"invoice_id\", \"description\", \"quantity\", \"unit_price\", \"total\"]\n",
    "\n",
    "    if invoices_to_append:\n",
    "        write_csv_append(LLM_INVOICES_PATH, invoices_to_append, invoice_fieldnames)\n",
    "        print(f\"Appended {len(invoices_to_append)} rows to {LLM_INVOICES_PATH}\")\n",
    "    if lineitems_to_append:\n",
    "        write_csv_append(LLM_LINEITEMS_PATH, lineitems_to_append, lineitem_fieldnames)\n",
    "        print(f\"Appended {len(lineitems_to_append)} rows to {LLM_LINEITEMS_PATH}\")\n",
    "\n",
    "    print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "752f38ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing [1/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (1).jpg\n",
      "Text-only extraction OK. Confidence = 0.9\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (1).jpg — method=text-only — valid=True — confidence=0.9\n",
      "\n",
      "Processing [2/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (1).pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (1).pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [3/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page2.jpg\n",
      "Validation failed or low confidence. Issues:\n",
      "  - total: missing\n",
      "  - lineitem[0].unit_price: missing\n",
      "  - lineitem[0].total: missing\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Still some issues after visual correction:\n",
      "  - total: missing\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page2.jpg — method=visual — valid=False — confidence=0.98\n",
      "\n",
      "Processing [4/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page2.pdf\n",
      "Validation failed or low confidence. Issues:\n",
      "  - total: missing\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Still some issues after visual correction:\n",
      "  - total: missing\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page2.pdf — method=visual — valid=False — confidence=0.98\n",
      "\n",
      "Processing [5/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page3.jpg\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page3.jpg — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [6/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page3.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page3.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [7/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page4.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (10)-page4.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [8/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (12).pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (12).pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [9/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (13).pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (13).pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [10/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (14).jpg\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (14).jpg — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [11/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (14).pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (14).pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [12/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (2).jpg\n",
      "Text-only extraction OK. Confidence = 0.88\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (2).jpg — method=text-only — valid=True — confidence=0.88\n",
      "\n",
      "Processing [13/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (2).pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (2).pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [14/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (3).jpg\n",
      "Text-only extraction OK. Confidence = 0.9\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (3).jpg — method=text-only — valid=True — confidence=0.9\n",
      "\n",
      "Processing [15/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (3).pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (3).pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [16/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (4)-page3.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (4)-page3.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [17/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (5).pdf\n",
      "Text-only extraction OK. Confidence = 0.9\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (5).pdf — method=text-only — valid=True — confidence=0.9\n",
      "\n",
      "Processing [18/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (6)-page1.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (6)-page1.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [19/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (6)-page2.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (6)-page2.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [20/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (7).jpg\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (7).jpg — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [21/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (7).pdf\n",
      "Text-only extraction OK. Confidence = 0.9\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (7).pdf — method=text-only — valid=True — confidence=0.9\n",
      "\n",
      "Processing [22/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page1.jpg\n",
      "Text-only extraction OK. Confidence = 0.9\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page1.jpg — method=text-only — valid=True — confidence=0.9\n",
      "\n",
      "Processing [23/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page1.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page1.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [24/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page2.jpg\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page2.jpg — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [25/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page2.pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page2.pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [26/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page3.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page3.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [27/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page4.jpg\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page4.jpg — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [28/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page4.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (8)-page4.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [29/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page1.jpg\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page1.jpg — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [30/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page1.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page1.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [31/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page2.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page2.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [32/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page3.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page3.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [33/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page4.jpg\n",
      "Text-only extraction OK. Confidence = 0.9\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page4.jpg — method=text-only — valid=True — confidence=0.9\n",
      "\n",
      "Processing [34/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page4.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER (9)-page4.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [35/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of ARPFIINVOEBTCHLASER.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [36/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20065629_from_Franks_Quality_Produce_18417572_22492.jpg\n",
      "extract_invoice_json raised an error: Model did not return valid JSON even after cleaning. Error: Expecting property name enclosed in double quotes: line 17 column 5 (char 451)\n",
      "Raw output:\n",
      "{\n",
      "  \"llm_invoices\": {\n",
      "    \"file_path\": \"C:\\\\Stealth AI\\\\Clean Reader\\\\data\\\\raw\\\\train\\\\Copy of Inv_20065629_from_Franks_Quality_Produce_18417572_22492.jpg\",\n",
      "    \"vendor\": \"frank's quality produce\",\n",
      "    \"date\": \"5/13/2025\",\n",
      "    \"total\": 109.26,\n",
      "    \"invoice_number\": null\n",
      "  },\n",
      "  \"llm_lineitems\": [\n",
      "    {\n",
      "      \"invoice_number\": null,\n",
      "      \"description\": \"tomato, roma\",\n",
      "      \"quantity\": 8.0,\n",
      "      \"unit_price\": 1.99,\n",
      "      \"total\": 15.92\n",
      "    ,\n",
      "    {\n",
      "      \"invoice_number\": null,\n",
      "      \"description\": \"onion, green\",\n",
      "      \"quantity\": 2.0,\n",
      "      \"unit_price\": 10.00,\n",
      "      \"total\": 20.00\n",
      "    },\n",
      "    {\n",
      "      \"invoice_number\": null,\n",
      "      \"description\": \"herbs, dill baby\",\n",
      "      \"quantity\": 1.0,\n",
      "      \"unit_price\": 11.00,\n",
      "      \"total\": 11.00\n",
      "    },\n",
      "    {\n",
      "      \"invoice_number\": null,\n",
      "      \"description\": \"onion, white\",\n",
      "      \"quantity\": 10.0,\n",
      "      \"unit_price\": 0.99,\n",
      "      \"total\": 9.90\n",
      "    },\n",
      "    {\n",
      "      \"invoice_number\": null,\n",
      "      \"description\": \"onion, italian red\",\n",
      "      \"quantity\": 6.0,\n",
      "      \"unit_price\": 0.99,\n",
      "      \"total\": 5.94\n",
      "    },\n",
      "    {\n",
      "      \"invoice_number\": null,\n",
      "      \"description\": \"avocado\",\n",
      "      \"quantity\": 1.0,\n",
      "      \"unit_price\": 39.00,\n",
      "      \"total\": 39.00\n",
      "    }\n",
      "  ],\n",
      "  \"confidence\": 0.95\n",
      "}\n",
      "Validation failed or low confidence. Issues:\n",
      "  - vendor: missing\n",
      "  - date: missing\n",
      "  - total: missing\n",
      "  - invoice_number: missing\n",
      "  - llm_lineitems missing or empty\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Visual correction successful.\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20065629_from_Franks_Quality_Produce_18417572_22492.jpg — method=visual — valid=True — confidence=0.98\n",
      "\n",
      "Processing [37/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20065629_from_Franks_Quality_Produce_18417572_22492.pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20065629_from_Franks_Quality_Produce_18417572_22492.pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [38/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20066901_from_Franks_Quality_Produce_18471648_18416.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20066901_from_Franks_Quality_Produce_18471648_18416.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [39/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20068140_from_Franks_Quality_Produce_18529019_11828.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20068140_from_Franks_Quality_Produce_18529019_11828.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [40/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20071084_from_Franks_Quality_Produce_18665028_7884.jpg\n",
      "Validation failed or low confidence. Issues:\n",
      "  - invoice_number: missing\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Visual correction successful.\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20071084_from_Franks_Quality_Produce_18665028_7884.jpg — method=visual — valid=True — confidence=0.9\n",
      "\n",
      "Processing [41/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20071084_from_Franks_Quality_Produce_18665028_7884.pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20071084_from_Franks_Quality_Produce_18665028_7884.pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [42/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20072265_from_Franks_Quality_Produce_18697771_15688.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20072265_from_Franks_Quality_Produce_18697771_15688.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [43/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20072898_from_Franks_Quality_Produce_18731344_15688.jpg\n",
      "Validation failed or low confidence. Issues:\n",
      "  - invoice_number: missing\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Still some issues after visual correction:\n",
      "  - lineitem[7].quantity: missing\n",
      "  - lineitem[7].unit_price: missing\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20072898_from_Franks_Quality_Produce_18731344_15688.jpg — method=visual — valid=False — confidence=0.99\n",
      "\n",
      "Processing [44/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20072898_from_Franks_Quality_Produce_18731344_15688.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20072898_from_Franks_Quality_Produce_18731344_15688.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [45/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20074433_from_Franks_Quality_Produce_18802791_20408 (1).pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20074433_from_Franks_Quality_Produce_18802791_20408 (1).pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [46/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20074433_from_Franks_Quality_Produce_18802791_20408.pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20074433_from_Franks_Quality_Produce_18802791_20408.pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [47/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20075310_from_Franks_Quality_Produce_18842235_13952.jpg\n",
      "Validation failed or low confidence. Issues:\n",
      "  - invoice_number: missing\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Visual correction successful.\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20075310_from_Franks_Quality_Produce_18842235_13952.jpg — method=visual — valid=True — confidence=1.0\n",
      "\n",
      "Processing [48/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20075310_from_Franks_Quality_Produce_18842235_13952.pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20075310_from_Franks_Quality_Produce_18842235_13952.pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [49/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20076301_from_Franks_Quality_Produce_18887473_13748 (1).pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20076301_from_Franks_Quality_Produce_18887473_13748 (1).pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [50/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20076301_from_Franks_Quality_Produce_18887473_13748.pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20076301_from_Franks_Quality_Produce_18887473_13748.pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [51/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20077622_from_Franks_Quality_Produce_18946409_7596 (1).pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20077622_from_Franks_Quality_Produce_18946409_7596 (1).pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [52/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20077622_from_Franks_Quality_Produce_18946409_7596.jpg\n",
      "Validation failed or low confidence. Issues:\n",
      "  - invoice_number: missing\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Visual correction successful.\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20077622_from_Franks_Quality_Produce_18946409_7596.jpg — method=visual — valid=True — confidence=0.95\n",
      "\n",
      "Processing [53/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20077622_from_Franks_Quality_Produce_18946409_7596.pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20077622_from_Franks_Quality_Produce_18946409_7596.pdf — method=text-only — valid=True — confidence=0.98\n",
      "\n",
      "Processing [54/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20078834_from_Franks_Quality_Produce_18994615_32132 (1).jpg\n",
      "Validation failed or low confidence. Issues:\n",
      "  - invoice_number: missing\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Visual correction successful.\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20078834_from_Franks_Quality_Produce_18994615_32132 (1).jpg — method=visual — valid=True — confidence=0.98\n",
      "\n",
      "Processing [55/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20078834_from_Franks_Quality_Produce_18994615_32132 (1).pdf\n",
      "Text-only extraction OK. Confidence = 0.95\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20078834_from_Franks_Quality_Produce_18994615_32132 (1).pdf — method=text-only — valid=True — confidence=0.95\n",
      "\n",
      "Processing [56/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20078834_from_Franks_Quality_Produce_18994615_32132.jpg\n",
      "Validation failed or low confidence. Issues:\n",
      "  - invoice_number: missing\n",
      "Calling visual_extract_invoice_json to attempt correction...\n",
      "Visual correction returned. Re-validating...\n",
      "Visual correction successful.\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20078834_from_Franks_Quality_Produce_18994615_32132.jpg — method=visual — valid=True — confidence=1.0\n",
      "\n",
      "Processing [57/57] file_path: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20078834_from_Franks_Quality_Produce_18994615_32132.pdf\n",
      "Text-only extraction OK. Confidence = 0.98\n",
      "Finished: C:\\Stealth AI\\Clean Reader\\data\\raw\\train\\Copy of Inv_20078834_from_Franks_Quality_Produce_18994615_32132.pdf — method=text-only — valid=True — confidence=0.98\n",
      "Appended 57 rows to c:\\Stealth AI\\Clean Reader\\data\\processed\\llm\\llm_invoices.csv\n",
      "Appended 234 rows to c:\\Stealth AI\\Clean Reader\\data\\processed\\llm\\llm_lineitems.csv\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_regex_invoices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a52157d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import wordninja\n",
    "\n",
    "# global runtime memory for vendors\n",
    "known_vendors = set()\n",
    "\n",
    "def normalize_vendor_name(vendor: str, known_vendors_list=None):\n",
    "    \"\"\"\n",
    "    Normalize and learn vendor names automatically.\n",
    "\n",
    "    Steps:\n",
    "    1. Remove punctuation and suffixes (Inc, LLC, etc.)\n",
    "    2. Check if a cleaned vendor matches any known vendor\n",
    "    3. If not found, use wordninja to split concatenated words\n",
    "    4. Add the newly normalized vendor to the known vendor list\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 0 – guard clause\n",
    "    if not vendor:\n",
    "        return \"\"\n",
    "\n",
    "    # Initialize if not passed\n",
    "    if known_vendors_list is None:\n",
    "        known_vendors_list = known_vendors  # uses global set\n",
    "\n",
    "    # Step 1 – basic cleaning\n",
    "    vendor_clean = vendor.strip()\n",
    "    vendor_clean = re.sub(r\"[^A-Za-z0-9]\", \"\", vendor_clean)\n",
    "    vendor_lower = vendor_clean.lower()\n",
    "\n",
    "    # Step 2 – remove suffixes\n",
    "    suffixes = [\"inc\", \"incorporated\", \"ltd\", \"llc\", \"company\", \"corp\", \"co\"]\n",
    "    for s in suffixes:\n",
    "        if vendor_lower.endswith(s):\n",
    "            vendor_lower = vendor_lower[: -len(s)]\n",
    "\n",
    "    vendor_lower = vendor_lower.strip()\n",
    "\n",
    "    # Step 3 – try known vendors first\n",
    "    for known in known_vendors_list:\n",
    "        if known.lower().replace(\" \", \"\") in vendor_lower:\n",
    "            return known  # found canonical form\n",
    "\n",
    "    # Step 4 – use wordninja to segment new vendors\n",
    "    words = wordninja.split(vendor_lower)\n",
    "    cleaned = \" \".join(words).title()\n",
    "\n",
    "    # Step 5 – store learned vendor name\n",
    "    known_vendors_list.add(cleaned)\n",
    "\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "238cd058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing vendor names...\n",
      "✅ Vendor names normalized and updated in c:\\Stealth AI\\Clean Reader\\data\\processed\\llm\\llm_invoices.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Paths ---\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "PROCESSED = os.path.join(ROOT, \"data\", \"processed\")\n",
    "LLM_FOLDER = os.path.join(PROCESSED, \"llm\")\n",
    "LLM_INVOICES_PATH = os.path.join(LLM_FOLDER, \"llm_invoices.csv\")\n",
    "\n",
    "# --- Load CSV ---\n",
    "if not os.path.exists(LLM_INVOICES_PATH):\n",
    "    raise FileNotFoundError(f\"File not found: {LLM_INVOICES_PATH}\")\n",
    "\n",
    "df = pd.read_csv(LLM_INVOICES_PATH)\n",
    "\n",
    "if \"vendor\" not in df.columns:\n",
    "    raise KeyError(\"The CSV does not contain a 'vendor' column.\")\n",
    "\n",
    "# --- Normalize vendor names ---\n",
    "print(\"Normalizing vendor names...\")\n",
    "df[\"vendor\"] = df[\"vendor\"].astype(str).apply(normalize_vendor_name)\n",
    "\n",
    "# --- Save updated file ---\n",
    "df.to_csv(LLM_INVOICES_PATH, index=False)\n",
    "\n",
    "print(f\"✅ Vendor names normalized and updated in {LLM_INVOICES_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8087b42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Vendors Found:\n",
      "\n",
      "Pacific Food Importers                   — 35 invoices\n",
      "Franks Quality Produce                   — 22 invoices\n",
      "\n",
      "Total unique vendors: 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Paths ---\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "PROCESSED = os.path.join(ROOT, \"data\", \"processed\")\n",
    "LLM_FOLDER = os.path.join(PROCESSED, \"llm\")\n",
    "LLM_INVOICES_PATH = os.path.join(LLM_FOLDER, \"llm_invoices.csv\")\n",
    "\n",
    "# --- Load CSV ---\n",
    "if not os.path.exists(LLM_INVOICES_PATH):\n",
    "    raise FileNotFoundError(f\"File not found: {LLM_INVOICES_PATH}\")\n",
    "\n",
    "df = pd.read_csv(LLM_INVOICES_PATH)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "if \"vendor\" not in df.columns:\n",
    "    raise KeyError(f\"'vendor' column not found. Found columns: {df.columns.tolist()}\")\n",
    "\n",
    "# --- Count unique vendors ---\n",
    "vendor_counts = (\n",
    "    df[\"vendor\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# figure out which column is the vendor name vs count\n",
    "col_names = list(vendor_counts.columns)\n",
    "vendor_col = col_names[0]\n",
    "count_col = col_names[1]\n",
    "\n",
    "# --- Display ---\n",
    "print(\"Unique Vendors Found:\\n\")\n",
    "for _, row in vendor_counts.iterrows():\n",
    "    vendor_name = row[vendor_col]\n",
    "    count_value = row[count_col]\n",
    "    print(f\"{vendor_name:<40} — {count_value} invoices\")\n",
    "\n",
    "print(f\"\\nTotal unique vendors: {len(vendor_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67182f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
