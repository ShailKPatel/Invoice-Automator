{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d07f0c8",
   "metadata": {},
   "source": [
    "# 02_data_modeling.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c93595",
   "metadata": {},
   "source": [
    "## Invoice and Line Item Extraction Summary\n",
    "\n",
    "**Goal:**\n",
    "Transform the cleaned OCR invoice data (`regex_cleaned_invoices.csv`) into two structured tables for easier downstream processing.\n",
    "\n",
    "**Output Files:**\n",
    "\n",
    "* `regex_invoices.csv` → one row per invoice\n",
    "  **Columns:** `file_path`, `invoice_id`, `vendor`, `date`, `total`, `invoice_number`\n",
    "* `regex_lineitems.csv` → one row per product line\n",
    "  **Columns:** `file_path`, `invoice_id`, `description`, `quantity`, `unit_price`, `total`\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "1. Separate invoice-level and item-level data for normalization.\n",
    "2. Enable consistent schema even when some invoices lack line item details.\n",
    "3. Prepare structured data for later LLM-based enrichment or verification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b234a992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created empty CSV files:\n",
      "Invoices → c:\\Stealth AI\\Clean Reader\\data\\processed\\regex_invoices.csv\n",
      "LineItems → c:\\Stealth AI\\Clean Reader\\data\\processed\\regex_lineitems.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define folder paths\n",
    "root_folder = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "processed_folder = os.path.join(root_folder, \"data\", \"processed\")\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Define output file paths\n",
    "invoices_csv = os.path.join(processed_folder, \"regex_invoices.csv\")\n",
    "lineitems_csv = os.path.join(processed_folder, \"regex_lineitems.csv\")\n",
    "\n",
    "# Create empty CSVs with defined schema\n",
    "invoices_cols = [\"file_path\", \"invoice_id\", \"vendor\", \"date\", \"total\", \"invoice_number\"]\n",
    "lineitems_cols = [\"file_path\", \"invoice_id\", \"description\", \"quantity\", \"unit_price\", \"total\"]\n",
    "\n",
    "pd.DataFrame(columns=invoices_cols).to_csv(invoices_csv, index=False)\n",
    "pd.DataFrame(columns=lineitems_cols).to_csv(lineitems_csv, index=False)\n",
    "\n",
    "print(\"Created empty CSV files:\")\n",
    "print(f\"Invoices → {invoices_csv}\")\n",
    "print(f\"LineItems → {lineitems_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d73227b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: File Presence Across Datasets\n",
      "Total files in train folder: 57\n",
      "Missing in regex_cleaned_invoices.csv: 0\n",
      "Missing in regex_invoices.csv: 0\n",
      "Missing in regex_lineitems.csv: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load cleaned invoice text table\n",
    "df = pd.read_csv(r\"..\\data\\processed\\regex_cleaned_invoices.csv\")\n",
    "\n",
    "# Define output paths\n",
    "root_folder = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "processed_folder = os.path.join(root_folder, \"data\", \"processed\", \"regex\")\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "invoices_csv = os.path.join(processed_folder, \"regex_invoices.csv\")\n",
    "lineitems_csv = os.path.join(processed_folder, \"regex_lineitems.csv\")\n",
    "\n",
    "invoices_data = []\n",
    "lineitems_data = []\n",
    "\n",
    "# Clean description function\n",
    "def clean_description(desc: str) -> str:\n",
    "    desc = desc.lower().strip()\n",
    "    desc = re.sub(r\"\\b\\d+\\s*[x#]\\s*\\d*\\s*(oz|lb|cs|ea|bn|bag)?\\b\", \"\", desc)\n",
    "    desc = re.sub(r\"\\b(cs|ea|bn|bag|lb|oz|#)\\b\", \"\", desc)\n",
    "    desc = re.sub(r\"[^a-z0-9\\s,]+\", \" \", desc)\n",
    "    desc = re.sub(r\"\\s+\", \" \", desc)\n",
    "    return desc.strip()\n",
    "\n",
    "# Loop through each invoice entry\n",
    "for _, row in df.iterrows():\n",
    "    text = str(row.get(\"cleaned_text\", \"\"))\n",
    "    file_path = row.get(\"file_path\", \"\")\n",
    "    invoice_id = int(row.get(\"id\", 0)) if not pd.isna(row.get(\"id\", 0)) else 0\n",
    "    vendor = row.get(\"vendor\", \"\")\n",
    "    date = row.get(\"date\", \"\")\n",
    "    total = row.get(\"total\", \"\")\n",
    "    invoice_number = int(row.get(\"invoice_number\", 0)) if not pd.isna(row.get(\"invoice_number\", 0)) else 0\n",
    "\n",
    "    # Invoice-level entry\n",
    "    invoices_data.append({\n",
    "        \"file_path\": file_path,\n",
    "        \"invoice_id\": invoice_id,\n",
    "        \"vendor\": vendor,\n",
    "        \"date\": date,\n",
    "        \"total\": total,\n",
    "        \"invoice_number\": invoice_number\n",
    "    })\n",
    "\n",
    "    # Line item extraction\n",
    "    line_pattern = re.compile(\n",
    "        r\"(\\d{4,6})?\\s*([\\d\\.]+)\\s+(?:ea|cs|bn|bag|lb|oz|#)?\\s*([A-Za-z0-9\\s\\+\\-,#&/]+?)\\s+(\\d+\\.\\d{2})\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    matches = line_pattern.findall(text)\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            _, qty, desc, total_price = match\n",
    "            try:\n",
    "                qty = int(float(qty))\n",
    "            except:\n",
    "                qty = 0\n",
    "            total_price = total_price.strip()\n",
    "            try:\n",
    "                unit_price = round(float(total_price) / float(qty), 2) if qty != 0 else \"\"\n",
    "            except:\n",
    "                unit_price = \"\"\n",
    "            clean_desc = clean_description(desc)\n",
    "            lineitems_data.append({\n",
    "                \"file_path\": file_path,\n",
    "                \"invoice_id\": invoice_id,\n",
    "                \"description\": clean_desc,\n",
    "                \"quantity\": qty,\n",
    "                \"unit_price\": unit_price,\n",
    "                \"total\": total_price\n",
    "            })\n",
    "    else:\n",
    "        # Add placeholder if no matches found\n",
    "        lineitems_data.append({\n",
    "            \"file_path\": file_path,\n",
    "            \"invoice_id\": invoice_id,\n",
    "            \"description\": \"\",\n",
    "            \"quantity\": 0,\n",
    "            \"unit_price\": \"\",\n",
    "            \"total\": \"\"\n",
    "        })\n",
    "\n",
    "# Save extracted data\n",
    "pd.DataFrame(invoices_data).to_csv(invoices_csv, index=False)\n",
    "pd.DataFrame(lineitems_data).to_csv(lineitems_csv, index=False)\n",
    "\n",
    "# Sanity Check Across All Processed Tables\n",
    "train_dir = os.path.join(root_folder, \"data\", \"raw\", \"train\")\n",
    "train_files = {os.path.basename(f).lower() for f in os.listdir(train_dir)}\n",
    "\n",
    "def get_filenames_from_column(df, column_name=\"file_path\"):\n",
    "    return {os.path.basename(str(f)).lower() for f in df[column_name].dropna() if isinstance(f, str)}\n",
    "\n",
    "cleaned_df = pd.read_csv(r\"..\\data\\processed\\regex_cleaned_invoices.csv\")\n",
    "invoices_df = pd.read_csv(invoices_csv)\n",
    "lineitems_df = pd.read_csv(lineitems_csv)\n",
    "\n",
    "cleaned_files = get_filenames_from_column(cleaned_df)\n",
    "invoices_files = get_filenames_from_column(invoices_df)\n",
    "lineitems_files = get_filenames_from_column(lineitems_df)\n",
    "\n",
    "missing_in_cleaned = train_files - cleaned_files\n",
    "missing_in_invoices = train_files - invoices_files\n",
    "missing_in_lineitems = train_files - lineitems_files\n",
    "\n",
    "print(\"Sanity Check: File Presence Across Datasets\")\n",
    "print(f\"Total files in train folder: {len(train_files)}\")\n",
    "print(f\"Missing in regex_cleaned_invoices.csv: {len(missing_in_cleaned)}\")\n",
    "print(f\"Missing in regex_invoices.csv: {len(missing_in_invoices)}\")\n",
    "print(f\"Missing in regex_lineitems.csv: {len(missing_in_lineitems)}\")\n",
    "\n",
    "if missing_in_cleaned:\n",
    "    print(\"\\nFiles missing from regex_cleaned_invoices.csv:\")\n",
    "    for f in sorted(missing_in_cleaned):\n",
    "        print(f)\n",
    "\n",
    "if missing_in_invoices:\n",
    "    print(\"\\nFiles missing from regex_invoices.csv:\")\n",
    "    for f in sorted(missing_in_invoices):\n",
    "        print(f)\n",
    "\n",
    "if missing_in_lineitems:\n",
    "    print(\"\\nFiles missing from regex_lineitems.csv:\")\n",
    "    for f in sorted(missing_in_lineitems):\n",
    "        print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4eaa4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: File Presence Across Datasets\n",
      "Total files in train: 57\n",
      "Missing in regex_cleaned_invoices.csv: 0\n",
      "Missing in regex_invoices.csv: 0\n",
      "Missing in regex_lineitems.csv: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "root_folder = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "processed_folder = os.path.join(root_folder, \"data\", \"processed\")\n",
    "regex_folder = os.path.join(root_folder, \"data\", \"processed\",\"regex\")\n",
    "train_folder = os.path.join(root_folder, \"data\", \"raw\", \"train\")\n",
    "\n",
    "# Load all three processed datasets\n",
    "cleaned_df = pd.read_csv(os.path.join(processed_folder, \"regex_cleaned_invoices.csv\"))\n",
    "invoices_df = pd.read_csv(os.path.join(regex_folder, \"regex_invoices.csv\"))\n",
    "lineitems_df = pd.read_csv(os.path.join(regex_folder, \"regex_lineitems.csv\"))\n",
    "\n",
    "# Create file name sets (normalize for comparison)\n",
    "train_files = {os.path.basename(f) for f in os.listdir(train_folder)}\n",
    "cleaned_files = {os.path.basename(f) for f in cleaned_df[\"file_path\"]}\n",
    "invoices_files = {os.path.basename(f) for f in invoices_df[\"file_path\"]}\n",
    "lineitems_files = {os.path.basename(f) for f in lineitems_df[\"file_path\"]}\n",
    "\n",
    "# Identify missing file names per dataset\n",
    "missing_in_cleaned = train_files - cleaned_files\n",
    "missing_in_invoices = train_files - invoices_files\n",
    "missing_in_lineitems = train_files - lineitems_files\n",
    "\n",
    "print(\"Sanity Check: File Presence Across Datasets\")\n",
    "print(f\"Total files in train: {len(train_files)}\")\n",
    "print(f\"Missing in regex_cleaned_invoices.csv: {len(missing_in_cleaned)}\")\n",
    "print(f\"Missing in regex_invoices.csv: {len(missing_in_invoices)}\")\n",
    "print(f\"Missing in regex_lineitems.csv: {len(missing_in_lineitems)}\")\n",
    "\n",
    "if missing_in_cleaned:\n",
    "    print(\"\\nFiles missing from regex_cleaned_invoices.csv:\")\n",
    "    for f in sorted(missing_in_cleaned):\n",
    "        print(f)\n",
    "\n",
    "if missing_in_invoices:\n",
    "    print(\"\\nFiles missing from regex_invoices.csv:\")\n",
    "    for f in sorted(missing_in_invoices):\n",
    "        print(f)\n",
    "\n",
    "if missing_in_lineitems:\n",
    "    print(\"\\nFiles missing from regex_lineitems.csv:\")\n",
    "    for f in sorted(missing_in_lineitems):\n",
    "        print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361bb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
